{
 "metadata": {
  "name": "C3. Random Forests - Analysis"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Random Forests - Analysis.\n",
      "===\n",
      "***\n",
      "\n",
      "## Introduction\n",
      "\n",
      "Our goal for this phase is to use the reduced variable data set from our exploration phase to create a model predicting human activity, using Random Forests.\n",
      "\n",
      "To remind ourselves, the variables we will use are:\n",
      "\n",
      "* tAccMean, tAccSD tJerkMean, tJerkSD\n",
      "* tGyroMean, tGyroSD tGyroJerkMean, tGyroJerkSD\n",
      "* fAccMean, fAccSD, fJerkMean, fJerkSD,\n",
      "* fGyroMean, fGyroSD, fGyroJerkMean, fGyroJerkSD,\n",
      "* fGyroMeanFreq, fGyroJerkMeanFreq fAccMeanFreq, fJerkMeanFreq\n",
      "* fAccSkewness, fAccKurtosis, fJerkSkewness, fJerkKurtosis\n",
      "* fGyroSkewness, fGyroKurtosis fGyroJerkSkewness, fGyroJerkKurtosis\n",
      "* angleAccGravity, angleJerkGravity angleGyroGravity, angleGyroJerkGravity\n",
      "* angleXGravity, angleYGravity, angleZGravity\n",
      "* subject, activity  \n",
      "\n",
      "Of these,   \n",
      "\n",
      "* all except the last two are numeric.  \n",
      "* 'subject' is an integer identifying a person, one of 21 from 1 to 27 with some missing. \n",
      "* 'activity' is a categorical variable - one of six activities identified earlier -  \n",
      "* 'sitting', 'standing', 'lying', 'walking', 'walking up', 'walking down'.  \n",
      "\n",
      "Why do we use Random Forests. We used Random Forests [4] in our model due to the relatively high accuracy of Random Forests and the complexity of our data.\n",
      "\n",
      "These are two major reasons to bring out the heavy artillery of Random Forests, especially when we have too many attrubutes even in a simplified set of attributes. \n",
      "\n",
      "## Methods\n",
      "\n",
      "\n",
      "### Expository Segue on experiment design \n",
      "\n",
      "[[ Should this be in the Exposition ? ]]\n",
      "\n",
      "Typically in analysing such data sets we are creating a model that uses the data we are given.  How do we know the model will work for other data?  The real answer is \"We don't\".  And there's no way we can be sure that we can create a model that will work for new data.  \n",
      "\n",
      "But what we **can** do is reduce the chances that we are creating an \"overfitted\" model. That is a technical term for a model that works wonderfully on the given data (fitted to it) and fails on the next data set that comes along.  There's a way to design our modeling experiment so we avoid that trap.  Here's how.  \n",
      "\n",
      "We take the data set and we keep some of the given data aside and we don't use it for modeling at all.  This \"held out\" set is called the test set.\n",
      "\n",
      "Then we take our remaining data and we further divide it so that we have a larger set called the training set and a smaller set we call the validation set.\n",
      "Then we create our model using the trainign set and look at how well it performs on the validation set (i.e. not counting the \"held out\" data).  \n",
      "We are allowed to tweak our modeling as much as we want using the training and validations sets but we are **not** allowed to look at the held out test set until we are ready to decalre we are done modeling.  Then we apply the model to our held out test data - when that test data also shows an acceptable error rate we have a good model.\n",
      "\n",
      "However if we get a bad error rate from the test data we have a problem.  We cannot keep tweaking the model to get a better test result because then we are simply overfitting again.  So what do we do?  We are allowed to mix up all the data, hold out a new test set which has to be different at least in part from the old one, and then we repeat the exercise.  In some cases when we are given a data set by a third party e are not shown the held out set, and we have to submit our model.\n",
      "\n",
      "The third party then applies our model to the held out test set and we don't get to mix it all up.  We only get one shot.  We're going to do that here and see how well we do."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Our experiment design\n",
      "\n",
      "We hold out the last 4 subjects in the data as a test set and the rest are used for our modeling. \n",
      "\n",
      "Of the 17 remaining subjects we use the first 12 subjects as the training set and remaining 5 as the validation set. \n",
      "\n",
      "[[ Following para may be too complex to explain here - we can skip this explanation for 0.1.  and create a separate doc on experimental design at next version.  It needs a more easy to understand and more detailed explanation. ]] \n",
      "\n",
      "We divided our data based on the 'subject' variable as we included \u2018subject\u2019 in our model and want to keep all test data separate.  \n",
      "If we used data divided on some other attribute then we would get data from all subjects in our training set, our validations set and our test set.  \n",
      "\n",
      "\n",
      "\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Training"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "# We used the randomForest package in R, using 5000 trees to train the model.  \n",
      "# Our results are as follows derived from the output of the randomForest() function in R.\n",
      "# in other saoftware we would use corresponding package and parameters"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "No. of trees: 5000  \n",
      "No. of variables tried at each split: 6   \n",
      "OOB estimate of error rate: 2.93%    \n",
      "OOB: \u201cOut of Bag\u201d refers to data not included in a particular bootstrap sample.    \n",
      "\n",
      "\n",
      "<image src=\"files/images/rfconfusionmat.png\" />\n",
      "\n",
      "\n",
      "\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffcNote: \n",
      "\n",
      "* OOB estimate of error rate is less than 3%   \n",
      "* Classification Errors are ~ 5% or less  \n",
      "\n",
      "What are these?  \n",
      "We're going to learn a simple way to interpret this data.\n",
      "\n",
      "[[ Need a segue on interpreting these models or a short circuit way to do this]]"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Results\n",
      "\n",
      "We use the predict() function using our model on our validation set and our test set and get the following results from our analysis of errors in the predictions.\n",
      "\n",
      "Prediction Errors and Computed Error Measures\n",
      "For the validation and test predictions we computed the Positive and Negative Predictive Value as well as Sensitivity and Specificity \n",
      "as formulas for error checking of our model. \n",
      "\n",
      "Code for computing these is available online. See [5].\n",
      "\ufffc\n",
      "### Key for tables  \n",
      "T+: True Positives  \n",
      "T-: True Negatives  \n",
      "F+: False Positives  \n",
      "F-: False Negatives  \n",
      "PosPred: Positive Predictive Value    \n",
      "NegPred: Negative Predictive Value    \n",
      "Sens: Sensitivity    \n",
      "Spec: Specificity    \n",
      "\n",
      "---\n",
      "\n",
      "<image src=\"files/images/rfvalsetpred.png\" />\n",
      "\n",
      "\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\n",
      "**\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffcMisclassification (Total, rounded) is 15%**  \n",
      "\n",
      "---\n",
      "\n",
      "<image src=\"files/images/rftestsetpred.png\" />\n",
      "\n",
      "\n",
      "**\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffc\ufffcMisclassification (Total, rounded) is 10%**\n",
      "\n",
      "---  \n",
      "\n",
      "\n",
      "## Conclusions\n",
      "\n",
      "We can make the following concrete conclusions looking at the above results.\n",
      "\n",
      "Random Forests give us satisfactory error rates and predictive power in this scenario.\n",
      "\n",
      "\ufffcUsing domain knowledge it is possible to get surprisingly high values of predictive measures, and low error rates on validation and test sets.  \n",
      "This is supported by the results, i.e. ~90% on predictive measures, OOB error estimates less than 5% and classification errors not greater than 5% per Confusion Matrix and 10% over all Misclassification on test set.   \n",
      "\n",
      "We only did this once and did not go back and forth tweaking the models.  Note that we stuck to the rules here and did not see the test set until we were done modeling.\n",
      "\n",
      "Focusing on magnitude and angle information for acceleration and jerk in the time and frequency domains gives us a model with surprising predictive power.  It's possible that a brute force model will give better predictive power but it would simply show us how to blindly apply the software.  If for some reason the model misbehaved or failed, we would not have any insight at all as to why.  Instead we used domain knowledge to focus on insight and in the process created a model with interpretive value.\n",
      "\n",
      "Model performance on the test set is better than on the validation set as seen in the two \u201cTotal\u201d rows above and each individual activity.\n",
      "\n",
      "Let's see how we might be able to improve the model in future.  It's always good to note the possible ways in which our model(s) might be deficient or incomplete or unfinished so we don't get overconfident about our models and overpromise what they can do.\n",
      "\n",
      "### Critique\n",
      "\n",
      "* Our model eliminated a number of Magnitude related attributes such as -mad, -max, -min also a number of Gyro related variables during the variable selection process using domain knowledge. These may be important but this was not tested.  We may want to look at that the next time we do this.\n",
      "\n",
      "* Variable importance should be investigated in detail - i.e. we really ought to look at how we can use the software to drill down on a much smaller, handful, of useful attributes and not 37."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## References\n",
      "\n",
      "[1] https://spark-public.s3.amazonaws.com/dataanalysis/samsungData.rda  \n",
      "[2] Human Activity Recognition Using Smartphones http://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones  \n",
      "[3] Android Developer Reference http://developer.android.com/reference/android/hardware/Sensor.html  \n",
      "[4] Random Forests http://en.wikipedia.org/wiki/Random_forest  \n",
      "[5] Code for computation of error measures https://gist.github.com/nborwankar/5131870  "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.core.display import HTML\n",
      "def css_styling():\n",
      "    styles = open(\"../styles/custom.css\", \"r\").read()\n",
      "    return HTML(styles)\n",
      "css_styling()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<style>\n",
        "    @font-face {\n",
        "        font-family: \"Computer Modern\";\n",
        "        src: url('http://mirrors.ctan.org/fonts/cm-unicode/fonts/otf/cmunss.otf');\n",
        "    }\n",
        "    div.cell{\n",
        "        width:800px;\n",
        "        margin-left:auto;\n",
        "        margin-right:auto;\n",
        "    }\n",
        "    h1 {\n",
        "        font-family: \"Charis SIL\", Palatino, serif;\n",
        "    }\n",
        "    h4{\n",
        "        margin-top:12px;\n",
        "        margin-bottom: 3px;\n",
        "       }\n",
        "    div.text_cell_render{\n",
        "        font-family: Computer Modern, \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;\n",
        "        line-height: 145%;\n",
        "        font-size: 120%;\n",
        "        width:800px;\n",
        "        margin-left:auto;\n",
        "        margin-right:auto;\n",
        "    }\n",
        "    .CodeMirror{\n",
        "            font-family: \"Source Code Pro\", source-code-pro,Consolas, monospace;\n",
        "    }\n",
        "    .prompt{\n",
        "        display: None;\n",
        "    }\n",
        "    .text_cell_render h5 {\n",
        "        font-weight: 300;\n",
        "        font-size: 16pt;\n",
        "        color: #4057A1;\n",
        "        font-style: italic;\n",
        "        margin-bottom: .5em;\n",
        "        margin-top: 0.5em;\n",
        "        display: block;\n",
        "    }\n",
        "    \n",
        "    .warning{\n",
        "        color: rgb( 240, 20, 20 )\n",
        "        }\n",
        "</style>\n",
        "<script>\n",
        "    MathJax.Hub.Config({\n",
        "                        TeX: {\n",
        "                           extensions: [\"AMSmath.js\"]\n",
        "                           },\n",
        "                tex2jax: {\n",
        "                    inlineMath: [ ['$','$'], [\"\\\\(\",\"\\\\)\"] ],\n",
        "                    displayMath: [ ['$$','$$'], [\"\\\\[\",\"\\\\]\"] ]\n",
        "                },\n",
        "                displayAlign: 'center', // Change this to 'center' to center equations.\n",
        "                \"HTML-CSS\": {\n",
        "                    styles: {'.MathJax_Display': {\"margin\": 4}}\n",
        "                }\n",
        "        });\n",
        "</script>"
       ],
       "output_type": "pyout",
       "prompt_number": 1,
       "text": [
        "<IPython.core.display.HTML at 0x109203a90>"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}